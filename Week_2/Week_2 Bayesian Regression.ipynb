{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjiP8JWG7J-9"
      },
      "source": [
        "1.1.10.1. Bayesian Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfEHDAfP646z",
        "outputId": "30d5024e-03fc-48f1-8eee-07f20d9406d6"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "X = [[0., 0.], [1., 1.], [2., 2.], [3., 3.]]\n",
        "Y = [0., 1., 2., 3.]\n",
        "reg = linear_model.BayesianRidge()\n",
        "reg.fit(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJS8lk4b7Net",
        "outputId": "8d494729-a3bc-47c7-993d-ac673118a151"
      },
      "outputs": [],
      "source": [
        "reg.predict([[1, 0.]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmgBfaE47QRq",
        "outputId": "32b95bc9-31fd-4f7d-8717-9c137ae5d37e"
      },
      "outputs": [],
      "source": [
        "reg.coef_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_NtVXFg7TkY"
      },
      "source": [
        "Bayesian Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aiywzLKm7T--",
        "outputId": "e67e3763-6272-4b8c-d56c-03c814a98fa6"
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn.linear_model import BayesianRidge, LinearRegression\n",
        "\n",
        "# #############################################################################\n",
        "# Generating simulated data with Gaussian weights\n",
        "np.random.seed(0)\n",
        "n_samples, n_features = 100, 100\n",
        "X = np.random.randn(n_samples, n_features)  # Create Gaussian data\n",
        "# Create weights with a precision lambda_ of 4.\n",
        "lambda_ = 4.\n",
        "w = np.zeros(n_features)\n",
        "# Only keep 10 weights of interest\n",
        "relevant_features = np.random.randint(0, n_features, 10)\n",
        "for i in relevant_features:\n",
        "    w[i] = stats.norm.rvs(loc=0, scale=1. / np.sqrt(lambda_))\n",
        "# Create noise with a precision alpha of 50.\n",
        "alpha_ = 50.\n",
        "noise = stats.norm.rvs(loc=0, scale=1. / np.sqrt(alpha_), size=n_samples)\n",
        "# Create the target\n",
        "y = np.dot(X, w) + noise\n",
        "\n",
        "# #############################################################################\n",
        "# Fit the Bayesian Ridge Regression and an OLS for comparison\n",
        "clf = BayesianRidge(compute_score=True)\n",
        "clf.fit(X, y)\n",
        "\n",
        "ols = LinearRegression()\n",
        "ols.fit(X, y)\n",
        "\n",
        "# #############################################################################\n",
        "# Plot true weights, estimated weights, histogram of the weights, and\n",
        "# predictions with standard deviations\n",
        "lw = 2\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.title(\"Weights of the model\")\n",
        "plt.plot(clf.coef_, color='lightgreen', linewidth=lw,\n",
        "         label=\"Bayesian Ridge estimate\")\n",
        "plt.plot(w, color='gold', linewidth=lw, label=\"Ground truth\")\n",
        "plt.plot(ols.coef_, color='navy', linestyle='--', label=\"OLS estimate\")\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Values of the weights\")\n",
        "plt.legend(loc=\"best\", prop=dict(size=12))\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.title(\"Histogram of the weights\")\n",
        "plt.hist(clf.coef_, bins=n_features, color='gold', log=True,\n",
        "         edgecolor='black')\n",
        "plt.scatter(clf.coef_[relevant_features], np.full(len(relevant_features), 5.),\n",
        "            color='navy', label=\"Relevant features\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.xlabel(\"Values of the weights\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.title(\"Marginal log-likelihood\")\n",
        "plt.plot(clf.scores_, color='navy', linewidth=lw)\n",
        "plt.ylabel(\"Score\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "\n",
        "\n",
        "# Plotting some predictions for polynomial regression\n",
        "def f(x, noise_amount):\n",
        "    y = np.sqrt(x) * np.sin(x)\n",
        "    noise = np.random.normal(0, 1, len(x))\n",
        "    return y + noise_amount * noise\n",
        "\n",
        "\n",
        "degree = 10\n",
        "X = np.linspace(0, 10, 100)\n",
        "y = f(X, noise_amount=0.1)\n",
        "clf_poly = BayesianRidge()\n",
        "clf_poly.fit(np.vander(X, degree), y)\n",
        "\n",
        "X_plot = np.linspace(0, 11, 25)\n",
        "y_plot = f(X_plot, noise_amount=0)\n",
        "y_mean, y_std = clf_poly.predict(np.vander(X_plot, degree), return_std=True)\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.errorbar(X_plot, y_mean, y_std, color='navy',\n",
        "             label=\"Polynomial Bayesian Ridge Regression\", linewidth=lw)\n",
        "plt.plot(X_plot, y_plot, color='gold', linewidth=lw,\n",
        "         label=\"Ground Truth\")\n",
        "plt.ylabel(\"Output y\")\n",
        "plt.xlabel(\"Feature X\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mer5rOCw7jHg"
      },
      "source": [
        "Curve Fitting with Bayesian Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "YWGMyviV7lAE",
        "outputId": "0fe17a56-8245-45a6-8281-e25056eb58f7"
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "\n",
        "\n",
        "def func(x): return np.sin(2*np.pi*x)\n",
        "\n",
        "\n",
        "# #############################################################################\n",
        "# Generate sinusoidal data with noise\n",
        "size = 25\n",
        "rng = np.random.RandomState(1234)\n",
        "x_train = rng.uniform(0., 1., size)\n",
        "y_train = func(x_train) + rng.normal(scale=0.1, size=size)\n",
        "x_test = np.linspace(0., 1., 100)\n",
        "\n",
        "\n",
        "# #############################################################################\n",
        "# Fit by cubic polynomial\n",
        "n_order = 3\n",
        "X_train = np.vander(x_train, n_order + 1, increasing=True)\n",
        "X_test = np.vander(x_test, n_order + 1, increasing=True)\n",
        "\n",
        "# #############################################################################\n",
        "# Plot the true and predicted curves with log marginal likelihood (L)\n",
        "reg = BayesianRidge(tol=1e-6, fit_intercept=False, compute_score=True)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
        "for i, ax in enumerate(axes):\n",
        "    # Bayesian ridge regression with different initial value pairs\n",
        "    if i == 0:\n",
        "        init = [1 / np.var(y_train), 1.]  # Default values\n",
        "    elif i == 1:\n",
        "        init = [1., 1e-3]\n",
        "        reg.set_params(alpha_init=init[0], lambda_init=init[1])\n",
        "    reg.fit(X_train, y_train)\n",
        "    ymean, ystd = reg.predict(X_test, return_std=True)\n",
        "\n",
        "    ax.plot(x_test, func(x_test), color=\"blue\", label=\"sin($2\\\\pi x$)\")\n",
        "    ax.scatter(x_train, y_train, s=50, alpha=0.5, label=\"observation\")\n",
        "    ax.plot(x_test, ymean, color=\"red\", label=\"predict mean\")\n",
        "    ax.fill_between(x_test, ymean-ystd, ymean+ystd,\n",
        "                    color=\"pink\", alpha=0.5, label=\"predict std\")\n",
        "    ax.set_ylim(-1.3, 1.3)\n",
        "    ax.legend()\n",
        "    title = \"$\\\\alpha$_init$={:.2f},\\\\ \\\\lambda$_init$={}$\".format(\n",
        "            init[0], init[1])\n",
        "    if i == 0:\n",
        "        title += \" (Default)\"\n",
        "    ax.set_title(title, fontsize=12)\n",
        "    text = \"$\\\\alpha={:.1f}$\\n$\\\\lambda={:.3f}$\\n$L={:.1f}$\".format(\n",
        "           reg.alpha_, reg.lambda_, reg.scores_[-1])\n",
        "    ax.text(0.05, -1.0, text, fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9n5Xucn7tw2"
      },
      "source": [
        "Automatic Relevance Determination Regression (ARD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qZ34K_7h7uVU",
        "outputId": "78cbaad3-61ae-4ea5-9947-a5b6339d3295"
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn.linear_model import ARDRegression, LinearRegression\n",
        "\n",
        "# #############################################################################\n",
        "# Generating simulated data with Gaussian weights\n",
        "\n",
        "# Parameters of the example\n",
        "np.random.seed(0)\n",
        "n_samples, n_features = 100, 100\n",
        "# Create Gaussian data\n",
        "X = np.random.randn(n_samples, n_features)\n",
        "# Create weights with a precision lambda_ of 4.\n",
        "lambda_ = 4.\n",
        "w = np.zeros(n_features)\n",
        "# Only keep 10 weights of interest\n",
        "relevant_features = np.random.randint(0, n_features, 10)\n",
        "for i in relevant_features:\n",
        "    w[i] = stats.norm.rvs(loc=0, scale=1. / np.sqrt(lambda_))\n",
        "# Create noise with a precision alpha of 50.\n",
        "alpha_ = 50.\n",
        "noise = stats.norm.rvs(loc=0, scale=1. / np.sqrt(alpha_), size=n_samples)\n",
        "# Create the target\n",
        "y = np.dot(X, w) + noise\n",
        "\n",
        "# #############################################################################\n",
        "# Fit the ARD Regression\n",
        "clf = ARDRegression(compute_score=True)\n",
        "clf.fit(X, y)\n",
        "\n",
        "ols = LinearRegression()\n",
        "ols.fit(X, y)\n",
        "\n",
        "# #############################################################################\n",
        "# Plot the true weights, the estimated weights, the histogram of the\n",
        "# weights, and predictions with standard deviations\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.title(\"Weights of the model\")\n",
        "plt.plot(clf.coef_, color='darkblue', linestyle='-', linewidth=2,\n",
        "         label=\"ARD estimate\")\n",
        "plt.plot(ols.coef_, color='yellowgreen', linestyle=':', linewidth=2,\n",
        "         label=\"OLS estimate\")\n",
        "plt.plot(w, color='orange', linestyle='-', linewidth=2, label=\"Ground truth\")\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Values of the weights\")\n",
        "plt.legend(loc=1)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.title(\"Histogram of the weights\")\n",
        "plt.hist(clf.coef_, bins=n_features, color='navy', log=True)\n",
        "plt.scatter(clf.coef_[relevant_features], np.full(len(relevant_features), 5.),\n",
        "            color='gold', marker='o', label=\"Relevant features\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.xlabel(\"Values of the weights\")\n",
        "plt.legend(loc=1)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.title(\"Marginal log-likelihood\")\n",
        "plt.plot(clf.scores_, color='navy', linewidth=2)\n",
        "plt.ylabel(\"Score\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "\n",
        "\n",
        "# Plotting some predictions for polynomial regression\n",
        "def f(x, noise_amount):\n",
        "    y = np.sqrt(x) * np.sin(x)\n",
        "    noise = np.random.normal(0, 1, len(x))\n",
        "    return y + noise_amount * noise\n",
        "\n",
        "\n",
        "degree = 10\n",
        "X = np.linspace(0, 10, 100)\n",
        "y = f(X, noise_amount=1)\n",
        "clf_poly = ARDRegression(threshold_lambda=1e5)\n",
        "clf_poly.fit(np.vander(X, degree), y)\n",
        "\n",
        "X_plot = np.linspace(0, 11, 25)\n",
        "y_plot = f(X_plot, noise_amount=0)\n",
        "y_mean, y_std = clf_poly.predict(np.vander(X_plot, degree), return_std=True)\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.errorbar(X_plot, y_mean, y_std, color='navy',\n",
        "             label=\"Polynomial ARD\", linewidth=2)\n",
        "plt.plot(X_plot, y_plot, color='gold', linewidth=2,\n",
        "         label=\"Ground Truth\")\n",
        "plt.ylabel(\"Output y\")\n",
        "plt.xlabel(\"Feature X\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPm6bLO2Cra//vAtHJwKMGb",
      "include_colab_link": true,
      "name": "Week2_Linear Models_1.1.10. Bayesian Regression",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
