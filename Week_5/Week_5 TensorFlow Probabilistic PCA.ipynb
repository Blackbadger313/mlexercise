{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK-PNVq5rrpJ"
      },
      "source": [
        "Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbM5dCFdUior"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import warnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "from tensorflow_probability import bijectors as tfb\n",
        "from tensorflow_probability import distributions as tfd\n",
        "\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3HgOrtnrv7w"
      },
      "source": [
        "The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gwc6maZifKnb"
      },
      "outputs": [],
      "source": [
        "def probabilistic_pca(data_dim, latent_dim, num_datapoints, stddv_datapoints):\n",
        "  w = yield tfd.Normal(loc=tf.zeros([data_dim, latent_dim]),\n",
        "                 scale=2.0 * tf.ones([data_dim, latent_dim]),\n",
        "                 name=\"w\")\n",
        "  z = yield tfd.Normal(loc=tf.zeros([latent_dim, num_datapoints]),\n",
        "                 scale=tf.ones([latent_dim, num_datapoints]),\n",
        "                 name=\"z\")\n",
        "  x = yield tfd.Normal(loc=tf.matmul(w, z),\n",
        "                       scale=stddv_datapoints,\n",
        "                       name=\"x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2whVRGHPdXNm"
      },
      "outputs": [],
      "source": [
        "num_datapoints = 5000\n",
        "data_dim = 2\n",
        "latent_dim = 1\n",
        "stddv_datapoints = 0.5\n",
        "\n",
        "concrete_ppca_model = functools.partial(probabilistic_pca,\n",
        "    data_dim=data_dim,\n",
        "    latent_dim=latent_dim,\n",
        "    num_datapoints=num_datapoints,\n",
        "    stddv_datapoints=stddv_datapoints)\n",
        "\n",
        "model = tfd.JointDistributionCoroutineAutoBatched(concrete_ppca_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OZubZZ8r-2k"
      },
      "source": [
        "The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b23iIkX8VVyn",
        "outputId": "18cc5254-e73e-4e0a-e0a9-c96ff0efa8b9"
      },
      "outputs": [],
      "source": [
        "actual_w, actual_z, x_train = model.sample()\n",
        "\n",
        "print(\"Principal axes:\")\n",
        "print(actual_w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDo5Yw2QseOL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ubJJvk0KVyVW",
        "outputId": "83f4468c-749f-4274-dd3f-c0b3955fd1fa"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x_train[0, :], x_train[1, :], color='blue', alpha=0.1)\n",
        "plt.axis([-20, 20, -20, 20])\n",
        "plt.title(\"Data set\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVaN7eQqshwr"
      },
      "source": [
        "Maximum a Posteoriori Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2AvQAYqIh6K"
      },
      "outputs": [],
      "source": [
        "w = tf.Variable(tf.random.normal([data_dim, latent_dim]))\n",
        "z = tf.Variable(tf.random.normal([latent_dim, num_datapoints]))\n",
        "\n",
        "target_log_prob_fn = lambda w, z: model.log_prob((w, z, x_train))\n",
        "losses = tfp.math.minimize(\n",
        "    lambda: -target_log_prob_fn(w, z),\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.05),\n",
        "    num_steps=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ya-XoAtpY474",
        "outputId": "a8a74f91-2e79-4814-a1ea-8bfe2bf228b1"
      },
      "outputs": [],
      "source": [
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "T3O6PHe3XX8a",
        "outputId": "cf9f22b8-e1c4-4e78-961f-c56766977512"
      },
      "outputs": [],
      "source": [
        "print(\"MAP-estimated axes:\")\n",
        "print(w)\n",
        "\n",
        "_, _, x_generated = model.sample(value=(w, z, None))\n",
        "\n",
        "plt.scatter(x_train[0, :], x_train[1, :], color='blue', alpha=0.1, label='Actual data')\n",
        "plt.scatter(x_generated[0, :], x_generated[1, :], color='red', alpha=0.1, label='Simulated data (MAP)')\n",
        "plt.legend()\n",
        "plt.axis([-20, 20, -20, 20])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-Ey7n3usyaB"
      },
      "source": [
        "Variational Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfXGOtI9g7bG"
      },
      "outputs": [],
      "source": [
        "qw_mean = tf.Variable(tf.random.normal([data_dim, latent_dim]))\n",
        "qz_mean = tf.Variable(tf.random.normal([latent_dim, num_datapoints]))\n",
        "qw_stddv = tfp.util.TransformedVariable(1e-4 * tf.ones([data_dim, latent_dim]),\n",
        "                                        bijector=tfb.Softplus())\n",
        "qz_stddv = tfp.util.TransformedVariable(\n",
        "    1e-4 * tf.ones([latent_dim, num_datapoints]),\n",
        "    bijector=tfb.Softplus())\n",
        "def factored_normal_variational_model():\n",
        "  qw = yield tfd.Normal(loc=qw_mean, scale=qw_stddv, name=\"qw\")\n",
        "  qz = yield tfd.Normal(loc=qz_mean, scale=qz_stddv, name=\"qz\")\n",
        "\n",
        "surrogate_posterior = tfd.JointDistributionCoroutineAutoBatched(\n",
        "    factored_normal_variational_model)\n",
        "\n",
        "losses = tfp.vi.fit_surrogate_posterior(\n",
        "    target_log_prob_fn,\n",
        "    surrogate_posterior=surrogate_posterior,\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.05),\n",
        "    num_steps=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "iTmklbFhdHiV",
        "outputId": "c291466a-05fd-498d-b24b-6599f45b576b"
      },
      "outputs": [],
      "source": [
        "print(\"Inferred axes:\")\n",
        "print(qw_mean)\n",
        "print(\"Standard Deviation:\")\n",
        "print(qw_stddv)\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "CpSsruVIqAv5",
        "outputId": "d27a0599-ac67-4c0c-d568-be2dbd9d0200"
      },
      "outputs": [],
      "source": [
        "posterior_samples = surrogate_posterior.sample(50)\n",
        "_, _, x_generated = model.sample(value=(posterior_samples))\n",
        "\n",
        "# It's a pain to plot all 5000 points for each of our 50 posterior samples, so\n",
        "# let's subsample to get the gist of the distribution.\n",
        "x_generated = tf.reshape(tf.transpose(x_generated, [1, 0, 2]), (2, -1))[:, ::47]\n",
        "\n",
        "plt.scatter(x_train[0, :], x_train[1, :], color='blue', alpha=0.1, label='Actual data')\n",
        "plt.scatter(x_generated[0, :], x_generated[1, :], color='red', alpha=0.1, label='Simulated data (VI)')\n",
        "plt.legend()\n",
        "plt.axis([-20, 20, -20, 20])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMVL5rxH1tUKNOGw7JXKsRy",
      "include_colab_link": true,
      "name": "Week5_TensorFlow_Probabilistic PCA",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
